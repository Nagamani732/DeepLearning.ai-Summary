{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "TF V1.x.x Inference using frozen graph",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagamani732/DeepLearning.ai-Summary/blob/master/TF_V1_x_x_Inference_using_frozen_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-_zizmKvyGK"
      },
      "source": [
        "!pip install tensorflow==1.15.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBuu0DsKvOXZ"
      },
      "source": [
        "import tensorflow as tf # Default graph is initialized when the library is imported\n",
        "from tensorflow.python.platform import gfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f1YGIaWvOXi"
      },
      "source": [
        "BATCH = 1\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "CHANNEL = 3\n",
        "MODEL_FILE = \"mobilenet_v2_1.0_224.pb\"\n",
        "INPUT_IMAGE = \"input_image.jpg\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7KhGGLyvOXj"
      },
      "source": [
        "def FetchInputOutput(sess):\n",
        "    inputs = []\n",
        "    for op in sess.graph.get_operations():\n",
        "        if (op.type == \"Placeholder\"):\n",
        "            inputs.append(op.name.replace('import/', ''))\n",
        "    if (len(inputs) == 0): \n",
        "        print(\"No inputs spotted.\")\n",
        "    else:\n",
        "        print(\"Found \", len(inputs), \" possible input(s): \")\n",
        "        for i in range(len(inputs)):\n",
        "                print(inputs[i])\n",
        "    node_inputs = []\n",
        "    outputs = []\n",
        "    for node in sess.graph_def.node:\n",
        "        for input in node.input:\n",
        "            node_inputs.append(input)\n",
        "    unlikely_output_types = [\"Const\", \"Assign\", \"NoOp\", \"Placeholder\"]\n",
        "    for op in sess.graph.get_operations():\n",
        "        if ((node_inputs.count(op.name) == 0) and (unlikely_output_types.count(op.type) == 0)):\n",
        "            outputs.append(op.name.replace('import/', ''))\n",
        "    if (len(outputs) == 0): \n",
        "        print(\"No outputs spotted.\")\n",
        "    else:\n",
        "        print(\"Found \", len(outputs), \" possible output(s): \")\n",
        "        for i in range(len(outputs)):\n",
        "                print(outputs[i])\n",
        "    return inputs, outputs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz1r0DnYvOXl",
        "outputId": "8372a4ee-783d-455c-d11f-63dff572d936"
      },
      "source": [
        "with tf.Graph().as_default() as graph:\n",
        "    with tf.Session() as sess:\n",
        "        # Load the graph in graph_def\n",
        "        print(\"\\nLoad graph\")\n",
        "        if not os.path.isfile(MODEL_FILE):\n",
        "            print('File does not exist')\n",
        "            sys.exit()\n",
        "        if not os.path.isfile(INPUT_IMAGE):\n",
        "            print('Input image does not exist') \n",
        "            sys.exit()\n",
        "        # Load the protobuf file from the disk and parse it to retrieve the unserialized graph_def\n",
        "        with gfile.FastGFile(MODEL_FILE,'rb') as f:\n",
        "            # Set graph to the default graph\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            # Import a graph_def into the current default Graph (In this case, the weights \n",
        "            # are (typically) embedded in the graph)\n",
        "            tf.import_graph_def(graph_def, name=\"\")\n",
        "            inputs, outputs = FetchInputOutput(sess)\n",
        "            input_names = []\n",
        "            output_names = []\n",
        "            for input in inputs:\n",
        "                input_names.append(input+':0')\n",
        "            for output in outputs:\n",
        "                output_names.append(output+':0')  \n",
        "            # Inference \n",
        "            _input = graph.get_tensor_by_name(input_names[0]) # Input Tensor\n",
        "            _output = graph.get_tensor_by_name(output_names[0]) # Output Tensor\n",
        "            print(\"\\nLoad Image...\")\n",
        "            # Read the image\n",
        "            oriimg = cv2.imread(INPUT_IMAGE, cv2.IMREAD_COLOR)\n",
        "            oriimg  = oriimg.astype(float)/255\n",
        "            resize_image = cv2.resize(oriimg,(WIDTH, HEIGHT))\n",
        "            net_image = np.reshape(resize_image, [BATCH, HEIGHT, WIDTH, CHANNEL])\n",
        "            #initialize_all_variables\n",
        "            tf.global_variables_initializer()\n",
        "            # Run model on single image\n",
        "            print(\"\\nRun model...\")\n",
        "            out = sess.run(_output, feed_dict= {_input:net_image})\n",
        "            top5 = tf.nn.top_k(out, 5)\n",
        "            print(\"Top5 Probablities...\\n\")\n",
        "            ind = sess.run(top5).indices\n",
        "            val = sess.run(top5).values\n",
        "            for i in range(0, 5):\n",
        "              if os.path.isfile('labels.txt'):\n",
        "                with open('labels.txt') as f:\n",
        "                  for line in f:\n",
        "                    index = ind[0][i]\n",
        "                    if str(index-1)+':' in line:\n",
        "                      print(line.strip() + \"  \" + str(val[0][i]))\n",
        "                      break\n",
        "              else:\n",
        "                print(ind[0][i], \" \", val[0][i])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Load graph\n",
            "Found  1  possible input(s): \n",
            "Placeholder\n",
            "Found  1  possible output(s): \n",
            "MobilenetV2/Predictions/Softmax\n",
            "\n",
            "Load Image...\n",
            "\n",
            "Run model...\n",
            "Top5 Probablities...\n",
            "\n",
            "208: 'Labrador retriever',  0.45184022\n",
            "222: 'kuvasz',  0.119468376\n",
            "170: 'Irish wolfhound',  0.033233084\n",
            "181: 'Bedlington terrier',  0.02925248\n",
            "182: 'Border terrier',  0.024229426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG1FQL2LBVP8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
